{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-11T05:54:43.471746Z",
     "start_time": "2025-06-11T05:54:43.390552Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "books = pd.read_csv('books_with_categories.csv')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T06:08:01.723978Z",
     "start_time": "2025-06-11T06:08:00.717673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"j-hartmann/emotion-english-distilroberta-base\",\n",
    "    top_k=None  # replaces return_all_scores=True\n",
    ")\n",
    "\n",
    "print(classifier(\"I love this\"))\n"
   ],
   "id": "5459c1ecb425213f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'joy', 'score': 0.9845667481422424}, {'label': 'surprise', 'score': 0.0049272035248577595}, {'label': 'sadness', 'score': 0.004531425889581442}, {'label': 'neutral', 'score': 0.003475300734862685}, {'label': 'anger', 'score': 0.0013875295408070087}, {'label': 'disgust', 'score': 0.0007134033949114382}, {'label': 'fear', 'score': 0.0003984913637395948}]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T06:20:48.788697Z",
     "start_time": "2025-06-11T06:20:48.783358Z"
    }
   },
   "cell_type": "code",
   "source": "books[\"description\"][0]",
   "id": "df0291ad91ba2f5b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T06:08:06.274874Z",
     "start_time": "2025-06-11T06:08:06.151398Z"
    }
   },
   "cell_type": "code",
   "source": "classifier(books[\"description\"][0])",
   "id": "3b50e58ae9cb1362",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mclassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbooks\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdescription\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\MyFile3.0\\ML\\Book-Recommender\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:159\u001B[39m, in \u001B[36mTextClassificationPipeline.__call__\u001B[39m\u001B[34m(self, inputs, **kwargs)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    125\u001B[39m \u001B[33;03mClassify the text(s) given as inputs.\u001B[39;00m\n\u001B[32m    126\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    156\u001B[39m \u001B[33;03m    If `top_k` is used, one such dictionary is returned per label.\u001B[39;00m\n\u001B[32m    157\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    158\u001B[39m inputs = (inputs,)\n\u001B[32m--> \u001B[39m\u001B[32m159\u001B[39m result = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    160\u001B[39m \u001B[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001B[39;00m\n\u001B[32m    161\u001B[39m _legacy = \u001B[33m\"\u001B[39m\u001B[33mtop_k\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m kwargs\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\MyFile3.0\\ML\\Book-Recommender\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1431\u001B[39m, in \u001B[36mPipeline.__call__\u001B[39m\u001B[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[39m\n\u001B[32m   1423\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[32m   1424\u001B[39m         \u001B[38;5;28miter\u001B[39m(\n\u001B[32m   1425\u001B[39m             \u001B[38;5;28mself\u001B[39m.get_iterator(\n\u001B[32m   (...)\u001B[39m\u001B[32m   1428\u001B[39m         )\n\u001B[32m   1429\u001B[39m     )\n\u001B[32m   1430\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1431\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrun_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\MyFile3.0\\ML\\Book-Recommender\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1437\u001B[39m, in \u001B[36mPipeline.run_single\u001B[39m\u001B[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[39m\n\u001B[32m   1436\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrun_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001B[32m-> \u001B[39m\u001B[32m1437\u001B[39m     model_inputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpreprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1438\u001B[39m     model_outputs = \u001B[38;5;28mself\u001B[39m.forward(model_inputs, **forward_params)\n\u001B[32m   1439\u001B[39m     outputs = \u001B[38;5;28mself\u001B[39m.postprocess(model_outputs, **postprocess_params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\MyFile3.0\\ML\\Book-Recommender\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:183\u001B[39m, in \u001B[36mTextClassificationPipeline.preprocess\u001B[39m\u001B[34m(self, inputs, **tokenizer_kwargs)\u001B[39m\n\u001B[32m    177\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(inputs, \u001B[38;5;28mlist\u001B[39m):\n\u001B[32m    178\u001B[39m     \u001B[38;5;66;03m# This is likely an invalid usage of the pipeline attempting to pass text pairs.\u001B[39;00m\n\u001B[32m    179\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    180\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mThe pipeline received invalid inputs, if you are trying to send text pairs, you can try to send a\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    181\u001B[39m         \u001B[33m'\u001B[39m\u001B[33m dictionary `\u001B[39m\u001B[33m{\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mtext\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m: \u001B[39m\u001B[33m\"\u001B[39m\u001B[33mMy text\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m, \u001B[39m\u001B[33m\"\u001B[39m\u001B[33mtext_pair\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m: \u001B[39m\u001B[33m\"\u001B[39m\u001B[33mMy pair\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m}` in order to send a text pair.\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    182\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m183\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mtokenizer_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\MyFile3.0\\ML\\Book-Recommender\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2867\u001B[39m, in \u001B[36mPreTrainedTokenizerBase.__call__\u001B[39m\u001B[34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[39m\n\u001B[32m   2865\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m._in_target_context_manager:\n\u001B[32m   2866\u001B[39m         \u001B[38;5;28mself\u001B[39m._switch_to_input_mode()\n\u001B[32m-> \u001B[39m\u001B[32m2867\u001B[39m     encodings = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mall_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2868\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   2869\u001B[39m     \u001B[38;5;28mself\u001B[39m._switch_to_target_mode()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\MyFile3.0\\ML\\Book-Recommender\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2927\u001B[39m, in \u001B[36mPreTrainedTokenizerBase._call_one\u001B[39m\u001B[34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001B[39m\n\u001B[32m   2924\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m   2926\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_valid_text_input(text):\n\u001B[32m-> \u001B[39m\u001B[32m2927\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   2928\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2929\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mor `List[List[str]]` (batch of pretokenized examples).\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2930\u001B[39m     )\n\u001B[32m   2932\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_valid_text_input(text_pair):\n\u001B[32m   2933\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   2934\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2935\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mor `List[List[str]]` (batch of pretokenized examples).\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2936\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "68eacab5bdc17aee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
